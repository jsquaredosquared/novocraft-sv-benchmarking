Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 64
Rules claiming more threads will be scaled down.
Select jobs to execute...
Execute 1 jobs...

[Fri Jul 26 21:50:14 2024]
localrule index_cram_file:
    input: ../../resources/alignment-files/HG002.bwa-mem2.cram
    output: ../../resources/alignment-files/HG002.bwa-mem2.cram.crai
    log: ../../logs/index_HG002.bwa-mem2_cram.log
    jobid: 0
    reason: Forced execution
    wildcards: sample=HG002, aligner=bwa-mem2
    threads: 8
    resources: mem_mb=8000, mem_mib=7630, disk_mb=67797, disk_mib=64657, tmpdir=/tmp/2304.1.slave.q

Activating conda environment: .snakemake/conda/18f90908a2ea392db940975d1cadf1c1_
[W::sam_hrecs_update_hashes] PG line with multiple ID tags. The first encountered was preferred - ID:bwa-mem2
[Fri Jul 26 21:55:29 2024]
Finished job 0.
1 of 1 steps (100%) done
Storing output in storage.
